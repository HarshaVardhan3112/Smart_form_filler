{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import PIL.Image\n",
    "import google.generativeai as genai\n",
    "from PIL import ImageDraw, ImageFont\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the API key from the .env file\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBSlkTW52fBvrHs-oByEb0AgSBo44qjm0A\"\n",
    "genai.configure(api_key=\"AIzaSyBSlkTW52fBvrHs-oByEb0AgSBo44qjm0A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Data String: Here's the structured data extracted from the provided image.  Note that many fields are missing from the provided document and cannot be inferred.\n",
      "\n",
      "- **Name:** N/A\n",
      "- **Date of Birth:** N/A\n",
      "- **Phone Number:** N/A\n",
      "- **Aadhaar Number:** N/A\n",
      "- **Gender:** N/A\n",
      "- **PAN Number:** N/A\n",
      "- **VID Number:** WJU4160073\n",
      "- **Address:** DNO-14-8-29, BHANOJI THOTA, GAJUWAKA, GAJUWAKA, VISAKHAPATNAM, ANDHRA PRADESH-530026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img = PIL.Image.open(\"backend\\\\uploads\\\\Harsha_voterIDBack.jpeg\")\n",
    "\n",
    "def extract_data(img):\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(\n",
    "        [\n",
    "            '''You are an expert in text extraction and formatting.\n",
    "        Given the following image, return structured data with these fields:\n",
    "        \n",
    "        - Name\n",
    "        - Date of Birth (format: DD-MM-YYYY)\n",
    "        - Phone Number (10-digit format)\n",
    "        - Aadhaar Number (12-digit format)\n",
    "        - Gender (MALE/FEMALE/OTHER)\n",
    "        - PAN Number (10-character alphanumeric)\n",
    "        - VID Number (16-digit format)\n",
    "        - Address\n",
    "\n",
    "\n",
    "        If any field is missing, try to infer it or return \"N/A\".\n",
    "        ''',\n",
    "            img,\n",
    "        ],\n",
    "        stream=True,\n",
    "    )\n",
    "    response.resolve()\n",
    "    return response.text\n",
    "try:\n",
    "    extracted_data_str = extract_data(img)\n",
    "    if not extracted_data_str:\n",
    "        raise ValueError(\"Error: No text extracted from image.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Extraction Failed: {e}\")\n",
    "print(\"Extracted Data String:\", extracted_data_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Data Dictionary: {'Name': 'N', 'Date of Birth': 'N/A', 'Phone Number': 'N/A', 'Aadhaar Number': 'N/A', 'Gender': 'N/A', 'PAN Number': 'N/A', 'VID Number': 'N/A', 'Address': 'DNO-14-8-29, BHANOJI THOTA, GAJUWAKA, GAJUWAKA, VISAKHAPATNAM, ANDHRA PRADESH- 530026'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def parse_extracted_text(extracted_text):\n",
    "    \"\"\"\n",
    "    Parses the extracted text and converts it into a structured dictionary.\n",
    "    \"\"\"\n",
    "    extracted_text = re.sub(r'\\*+', '', extracted_text)\n",
    "    \n",
    "    fields = {\n",
    "        \"Name\": r\"Name:\\s*([A-Za-z\\s]+)\",  # Only alphabets and spaces\n",
    "        \"Date of Birth\": r\"Date of Birth:\\s*(\\d{2}-\\d{2}-\\d{4})\",\n",
    "        \"Phone Number\": r\"Phone Number:\\s*(\\d{10})\",\n",
    "        # Allows spaces\n",
    "        \"Aadhaar Number\": r\"Aadhaar Number:\\s*(\\d{4}\\s?\\d{4}\\s?\\d{4})\",\n",
    "        \"Gender\": r\"Gender:\\s*(MALE|FEMALE|OTHER)\",\n",
    "        # PAN format strict\n",
    "        \"PAN Number\": r\"PAN Number:\\s*([A-Z]{5}[0-9]{4}[A-Z])\",\n",
    "        \"VID Number\": r\"VID Number:\\s*(\\d{16})\",\n",
    "        \"Address\": r\"Address:\\s*([\\w\\s,.-]+?)(?:\\s*(\\d{6}))?\\s*(?=\\n|$)\"\n",
    "        \n",
    "    }\n",
    "    \n",
    "    extracted_data = {}\n",
    "\n",
    "    for key, pattern in fields.items():\n",
    "        match = re.search(pattern, extracted_text)\n",
    "        if key == \"Address\" and match:\n",
    "            address_part = match.group(1).strip().upper()\n",
    "            pincode_part = match.group(2)  # pincode part\n",
    "            extracted_data[key] = f\"{address_part} {pincode_part}\".strip() if pincode_part else address_part\n",
    "        else:\n",
    "            extracted_data[key] = match.group(1).strip().upper() if match else \"N/A\"\n",
    "\n",
    "    return extracted_data\n",
    "\n",
    "structured_data = parse_extracted_text(extracted_data_str)\n",
    "print(\"Extracted Data Dictionary:\", structured_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdf2image\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "def extract_text_from_pdf_images(pdf_path):\n",
    "    images = pdf2image.convert_from_path(pdf_path)\n",
    "    for page_num, image in enumerate(images):\n",
    "        text = pytesseract.image_to_string(image)\n",
    "        # print(f\"Page {page_num + 1} OCR Text:\\n\", text)\n",
    "\n",
    "# Example Usage\n",
    "extract_text_from_pdf_images(\"backend\\\\uploads\\\\sbi_bank_form.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positions for '.name*': [(1, 71, 644, 69, 12)]\n",
      "Positions for '.date of birth*': [(1, 71, 740, 120, 31)]\n",
      "Positions for '.gender*': [(1, 601, 739, 77, 13)]\n",
      "Positions for 'address*': [(2, 71, 618, 70, 12), (2, 71, 932, 70, 13), (7, 79, 1579, 69, 12)]\n",
      "Positions for '.pan*': [(1, 71, 2054, 63, 12)]\n",
      "Positions for 'mobile no.': [(1, 71, 2166, 74, 12)]\n"
     ]
    }
   ],
   "source": [
    "import pdf2image\n",
    "import pytesseract\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def find_multiple_word_positions(pdf_path, search_words):\n",
    "    images = pdf2image.convert_from_path(pdf_path)\n",
    "    word_positions = {word.lower(): [] for word in search_words}  # Initialize dictionary\n",
    "\n",
    "    for page_num, image in enumerate(images):\n",
    "        img_cv = np.array(image)\n",
    "        img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "        img_gray = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "\n",
    "        # Perform OCR with bounding box detection\n",
    "        data = pytesseract.image_to_data(img_gray, output_type=pytesseract.Output.DICT)\n",
    "\n",
    "        # Clean text data\n",
    "        cleaned_text = [re.sub(r'[0-9:]', '', word) for word in data[\"text\"]]\n",
    "        data[\"text\"] = cleaned_text\n",
    "\n",
    "        # Call the function to merge multi-line fields\n",
    "        merged_data = merge_multiline_fields(data)\n",
    "\n",
    "        # print(f\"Page {page_num + 1} OCR Data:\\n\", merged_data[\"text\"])\n",
    "\n",
    "        for i, word in enumerate(merged_data[\"text\"]):\n",
    "            word_lower = word.lower().strip()\n",
    "            # word_lower = re.sub(r'\\W+', '', word.lower().strip())           # Remove non-alphanumeric characters\n",
    "            if word_lower in word_positions:  # Check if word is in the search list\n",
    "                x, y, w, h = merged_data[\"left\"][i], merged_data[\"top\"][i], merged_data[\"width\"][i], merged_data[\"height\"][i]\n",
    "                # Store page number & coordinates\n",
    "                word_positions[word_lower].append((page_num + 1, x, y, w, h))\n",
    "\n",
    "    return word_positions\n",
    "\n",
    "# Function to merge multi-line fields\n",
    "def merge_multiline_fields(data, threshold_x=70, threshold_y=18):\n",
    "    merged_fields = {\n",
    "        \"text\": [],\n",
    "        \"left\": [],\n",
    "        \"top\": [],\n",
    "        \"width\": [],\n",
    "        \"height\": []\n",
    "    }\n",
    "    temp_field = \"\"\n",
    "    last_x, last_y = 0, 0\n",
    "    temp_left, temp_top, temp_width, temp_height = 0, 0, 0, 0\n",
    "\n",
    "    for i, word in enumerate(data[\"text\"]):\n",
    "        if word:\n",
    "            x, y, w, h = data[\"left\"][i], data[\"top\"][i], data[\"width\"][i], data[\"height\"][i]\n",
    "\n",
    "            if temp_field:  # If there's already a word in progress\n",
    "                if abs(y - last_y) < threshold_y and abs(x - (last_x + temp_width)) < threshold_x:\n",
    "                    temp_field += \" \" + word  # Merge words horizontally\n",
    "                    temp_width = x + w - temp_left  # Update width to include new word\n",
    "                    temp_height = max(temp_height, h)  # Update height to the maximum height\n",
    "                else:\n",
    "                    merged_fields[\"text\"].append(temp_field)\n",
    "                    merged_fields[\"left\"].append(temp_left)\n",
    "                    merged_fields[\"top\"].append(temp_top)\n",
    "                    merged_fields[\"width\"].append(temp_width)\n",
    "                    merged_fields[\"height\"].append(temp_height)\n",
    "                    temp_field = word  # Start new phrase\n",
    "                    temp_left, temp_top, temp_width, temp_height = x, y, w, h\n",
    "            else:\n",
    "                temp_field = word  # Initialize first word\n",
    "                temp_left, temp_top, temp_width, temp_height = x, y, w, h\n",
    "\n",
    "            last_x, last_y = x, y  # Update position reference\n",
    "\n",
    "    if temp_field:\n",
    "        merged_fields[\"text\"].append(temp_field)\n",
    "        merged_fields[\"left\"].append(temp_left)\n",
    "        merged_fields[\"top\"].append(temp_top)\n",
    "        merged_fields[\"width\"].append(temp_width)\n",
    "        merged_fields[\"height\"].append(temp_height)\n",
    "\n",
    "    return merged_fields\n",
    "\n",
    "# Example Usage\n",
    "pdf_path = \"backend\\\\uploads\\\\sbi_bank_form.pdf\"\n",
    "search_words = [\".name*\", \".date of birth*\", \".gender*\", \"address*\", \".pan*\", \"mobile no.\"]  # List of words to find\n",
    "positions = find_multiple_word_positions(pdf_path, search_words)\n",
    "\n",
    "# Print detected positions\n",
    "for word, pos_list in positions.items():\n",
    "    print(f\"Positions for '{word}':\", pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def highlight_detected_words(pdf_path, search_words):\n",
    "#     images = pdf2image.convert_from_path(pdf_path)\n",
    "    \n",
    "#     for page_num, image in enumerate(images):\n",
    "#         img_cv = np.array(image)\n",
    "#         img_gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)\n",
    "#         data = pytesseract.image_to_data(\n",
    "#             img_gray, output_type=pytesseract.Output.DICT)\n",
    "#         cleaned_text = [re.sub(r'[0-9:]', '', word) for word in data[\"text\"]]\n",
    "#         data[\"text\"] = cleaned_text\n",
    "#         merged_data = merge_multiline_fields(data)\n",
    "\n",
    "\n",
    "#         for i, word in enumerate(merged_data[\"text\"]):\n",
    "#             word_lower = word.lower().strip()\n",
    "#             if word_lower in [w.lower() for w in search_words]:\n",
    "#                 x, y, w, h = merged_data[\"left\"][i], merged_data[\"top\"][i], merged_data[\"width\"][i], merged_data[\"height\"][i]\n",
    "#                 cv2.rectangle(img_cv, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green box\n",
    "\n",
    "#         plt.figure(figsize=(10, 8))\n",
    "#         plt.imshow(cv2.cvtColor(img_cv, cv2.COLOR_BGR2RGB))\n",
    "#         plt.title(f\"Highlighted Words on Page {page_num + 1}\")\n",
    "#         plt.axis(\"off\")\n",
    "#         plt.show()\n",
    "\n",
    "# # Example Usage\n",
    "# highlight_detected_words(pdf_path, search_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form filled successfully. Output saved to output_filled_form.pdf\n",
      "Filled form saved to output_filled_form.pdf\n"
     ]
    }
   ],
   "source": [
    "def fill_form_with_extracted_data(pdf_path, extracted_data, word_positions, output_pdf_path):\n",
    "    try:\n",
    "        if not isinstance(extracted_data, dict):\n",
    "            raise ValueError(\"extracted_data should be a dictionary\")\n",
    "\n",
    "        images = pdf2image.convert_from_path(pdf_path)  # Convert PDF to images\n",
    "        font_path = \"arialbd.ttf\"  # Replace with the path to your TrueType font file\n",
    "        font_size = 30\n",
    "        font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "        mapping = {\n",
    "            \".name*\": \"Name\",\n",
    "            \".date of birth*\": \"Date of Birth\",\n",
    "            \".pan*\": \"PAN Number\",\n",
    "            \".gender*\": \"Gender\",\n",
    "            \"address*\": \"Address\",\n",
    "            \"mobile no.\": \"Phone Number\",\n",
    "            \"First Name\": \"First Name\",\n",
    "            \"Last Name\": \"Last Name\",\n",
    "        }\n",
    "\n",
    "        # Calculate a fixed width for each letter\n",
    "        sample_letter = \"G\"  # Use \"A\" or any character as a reference\n",
    "        fixed_letter_width = font.getbbox(sample_letter)[2] + 13  # Width of \"A\" + spacing\n",
    "\n",
    "        for page_num, image in enumerate(images):\n",
    "            img_cv = np.array(image)\n",
    "            img_pil = image.copy()\n",
    "            draw = ImageDraw.Draw(img_pil)\n",
    "\n",
    "            for word, pos_list in word_positions.items():\n",
    "                extracted_key = next(\n",
    "                    (mapping[key] for key in mapping.keys() if key.lower() in word.lower()), None\n",
    "                )\n",
    "                if extracted_key and extracted_data.get(extracted_key) and extracted_data[extracted_key] != \"NOT FOUND\":\n",
    "                    value_to_fill = extracted_data[extracted_key]\n",
    "\n",
    "                    for (page, x, y, w, h) in pos_list:\n",
    "                        if page == page_num + 1:\n",
    "                            x_offset = x + 225  # Adjust the x_offset as needed\n",
    "                            y_offset = y - 10  # Adjust the y_offset as needed\n",
    "                            available_width = 100 # Maximum width for the address, adjust as needed\n",
    "\n",
    "                            if extracted_key == \"Address\":\n",
    "                                # Wrap the address text\n",
    "                                address = value_to_fill[:74]\n",
    "                                # Wrap the truncated address text\n",
    "                                wrapped_text = textwrap.fill(address, width=40)\n",
    "                                lines = wrapped_text.splitlines()\n",
    "                                line_height = font.getbbox(\"A\")[3] # Approximate line height\n",
    "\n",
    "                                for line in lines:\n",
    "                                    x_line_offset = x_offset  # Reset x_line_offset for each line\n",
    "                                    for letter in line:\n",
    "                                        draw.text((x_line_offset, y_offset), letter, fill=\"Blue\", font=font)\n",
    "                                        x_line_offset += fixed_letter_width    # Letter spacing for address\n",
    "                                    y_offset += line_height + 22  # Adjust vertical spacing\n",
    "                            else:\n",
    "                                # For other fields, draw text normally\n",
    "                                for letter in value_to_fill:\n",
    "                                    draw.text((x_offset, y_offset), letter, fill=\"Blue\", font=font)\n",
    "                                    x_offset += fixed_letter_width    # Adjust the spacing between letters\n",
    "\n",
    "            images[page_num] = img_pil  # Update image\n",
    "\n",
    "        images[0].save(output_pdf_path, save_all=True, append_images=images[1:])\n",
    "        print(f\"Form filled successfully. Output saved to {output_pdf_path}\")\n",
    "        return output_pdf_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error filling form: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "pdf_path = \"backend\\\\uploads\\\\sbi_bank_form.pdf\"\n",
    "output_pdf_path = \"output_filled_form.pdf\"\n",
    "fill_form_with_extracted_data(pdf_path, structured_data, positions, output_pdf_path)\n",
    "\n",
    "print(f\"Filled form saved to {output_pdf_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
